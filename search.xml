<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>建立博客的初衷</title>
      <link href="/2019/12/10/jian-li-bo-ke-de-chu-zhong/"/>
      <url>/2019/12/10/jian-li-bo-ke-de-chu-zhong/</url>
      
        <content type="html"><![CDATA[<h1 id="聊聊建立博客的初衷与对未来的展望"><a href="#聊聊建立博客的初衷与对未来的展望" class="headerlink" title="聊聊建立博客的初衷与对未来的展望"></a>聊聊建立博客的初衷与对未来的展望</h1><h2 id="一、为什么建立个人博客"><a href="#一、为什么建立个人博客" class="headerlink" title="一、为什么建立个人博客"></a>一、为什么建立个人博客</h2><p>我和大多数人一样，是个平凡而普通的人。在过去的二十多年里，我过着普通的生活、接受着普通的教育，有自己的想法却又不付诸行动，是一条不折不扣的咸鱼🙈。</p><p>在大学中因为种种原因没有参加校招而去了一家小公司，当时看重的是这家公司的发展前景，但是现实还是给我上了一课，其中的酸涩只有经历过的人才能体会。因此如果你是快要毕业的计算机专业学生且打算从事专业对口的工作，我<strong>强烈建议你千万不要去小公司</strong>（也不是绝对，我会专门写一篇博客说说我的理由）！当初是我自己的选择，因此我不后悔，我觉得：</p><ol><li><strong>作为一个成年人，任何的选择都应该做出充分的考虑，是权衡利弊后最终的结果，理应为此做好最坏的打算</strong>；</li><li><strong>我相信任何的经历都是独一无二的，都是你成长过程中宝贵的财富</strong>；</li><li><strong>你的每段经历都会对你的未来产生潜移默化的影响，这种未知的可能性让人妙不可言</strong>。</li></ol><p>19年8月份我裸辞了，及时止损😎。一是因为工作的原因想休息休息，对于二十几岁的我来说，<strong>身体上的劳累尚可接受，心理上的压抑让我寝食难安</strong>；另外一个原因是想换个方向。</p><p>我大学学的是计算机专业（普通二本），我自认为在我们班中专业能力还算靠前，毕业后的第一份工作也是Java开发，但是因为我自己疏于学习，加之这家公司不使用主流的框架、没有任何的代码规范、不适用任何的版本控制工具等等等等的原因，让我觉得这段工作没有让我在技术上有太大的提升，已经显著落后与同龄人。这令我对重新找一份<strong>我满意</strong>的Java开发工作没有太大的信心；另一方面也是因为第一段工作的原因让我对<strong>数据分析</strong>产生了浓厚的兴趣，因此想找一份数据分析方向的工作。</p><p>在家自学了三个月，每天看看学习视频、写写代码、读读书、刷刷剧、炒炒股、陪朋友打打游戏、做做饭、晒晒太阳、睡睡懒觉，日子过得也还算充实有趣。19年11月底我重新找到了一个还算比较满意数据分析工作，<strong>新的工作、新的同事、新的生活</strong>，我觉得我也应该做出些改变。</p><p>我是一个性格比较内敛的人，不喜欢拍照，留下的照片也寥寥无几，但是在过去的二十年，照片绝对是记录生活的一个很好的载体。我现在已经回忆不起我在过去的某个时间段做过什么事情，如果你喜欢写日记，那就坚持下去，如果你害怕日记写成流水账就多拍拍照片/vlog，因为这些<strong>具象化</strong>的东西会快速调起你的回忆，也帮你记录生活。</p><p>我自觉还算是一个对技术<strong>充满渴望</strong>的人，所以个人博客可能对我来说是个不错的选择。博客不仅记录我学习、思考的过程，同时也可以记录一下日常的生活，对于我来说，建立博客的好处有一下几点：</p><ul><li>我有拖延症，博客可以从一方面push我不断学习新的知识</li><li>我自己的理解能力尚可，表达能力欠佳，写作可以锻炼我的思维与表达能力</li><li>能加深自己对知识的理解，形成自己的知识体系</li><li>算是对个人知识、个人生活的归档与记录，方便日后查阅，同时在技术上也可以顺便解决他人类似的问题</li></ul><p>最后，努力奋斗，努力做一个<code>自由而无用</code>的人😆。</p><h2 id="二、对未来的展望"><a href="#二、对未来的展望" class="headerlink" title="二、对未来的展望"></a>二、对未来的展望</h2><h3 id="2-1、工作上"><a href="#2-1、工作上" class="headerlink" title="2.1、工作上"></a>2.1、工作上</h3><p>从<code>短期</code>来看，尽快熟悉新的工作，尽快建立通用的<code>数据分析思维</code>，尽早掌握初级分析师的全部技能</p><p>以<code>2020</code>年来说，希望自己重拾<code>数学</code>知识，在打好<code>数学基础</code>的同时学完<code>统计学</code>与<code>机器学习</code>的基础知识</p><p>从<code>长期</code>来看，先掌握<code>数据采集-数据清洗-数据建模-数据分析</code>整套流程的通用技能，再对每个过程做更深入的了解，包括且不限于<code>数据埋点、数据仓库、机器学习、深度学习、分布式爬虫、算法....</code></p><h2 id="2-2、生活上"><a href="#2-2、生活上" class="headerlink" title="2.2、生活上"></a>2.2、生活上</h2><ul><li>慢慢改掉自己拖延的坏习惯</li><li>减少零碎与娱乐信息的获取</li><li>维护和谐的家庭与社交关系</li><li>保持好奇心，保持身材</li><li>多读上市公司研报，建立自己的经济知识体系</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KNN算法-1-KNN简介</title>
      <link href="/2019/12/10/knn-suan-fa-1-knn-jian-jie/"/>
      <url>/2019/12/10/knn-suan-fa-1-knn-jian-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="KNN入门"><a href="#KNN入门" class="headerlink" title="KNN入门"></a>KNN入门</h1><p>最近开始学习机器学习的有关知识，对于初学者来说，KNN算法因朴素的思想其被认为是最适合入门的机器学习算法，没有之一。本篇文章主要介绍KNN算法的基本知识与核心思想。</p><h2 id="1、KNN简介"><a href="#1、KNN简介" class="headerlink" title="1、KNN简介"></a>1、KNN简介</h2><p>kNN (k-NearestNeighbor)，也就是k最近邻算法，这是一种有监督的学习算法，该算法既可以针对离散因变量做分类，又可以对连续因变量做预测</p><h2 id="2、核心思想"><a href="#2、核心思想" class="headerlink" title="2、核心思想"></a>2、核心思想</h2><blockquote><p>近朱者赤，近墨者黑</p></blockquote><p>举个简单的例子，以下是支付宝对<code>芝麻信用分</code>的定义：</p><blockquote><p>依据用户各类消费及行为数据，结合互联网金融借贷信息，运用云计算及机器学习等技术，通过逻辑回归、决策树、随机森林等模型算法，对各维度数据进行综合处理和评估，在用户信用历史、行为偏好、履约能力、身份特质、<strong>人脉关系</strong>五个维度客观呈现个人信用状况的综合分值。</p></blockquote><p>注意<code>人脉关系</code>这个维度，用通俗的话说就是你好友中混的最差的哥们都开玛莎拉蒂，月消费几十万，那么你的消费履约能力应该也不差</p><p><img src="https://i.loli.net/2019/12/15/okjqyCK8fHAne2r.png" alt="KNN原理图片示例"></p><p>如图所示，KNN算法的本质就是寻找𝑘个最近样本，然后基于最近样本做“预测”。对于离散型的因变量来说，从𝑘个最近的已知类别样本中挑选出频率最高的类别用于未知样本的判断；对于连续型的因变量来说，则是将𝑘个最近的已知样本均值用作未知样本的预测。</p><h2 id="3、算法步骤-amp-关键点"><a href="#3、算法步骤-amp-关键点" class="headerlink" title="3、算法步骤&amp;关键点"></a>3、算法步骤&amp;关键点</h2><ul><li>确定未知样本近邻的个数𝑘值。</li></ul><ul><li>根据某种度量样本间相似度的指标（如欧氏距离）将每一个未知类别样本的最近𝑘个已知样本搜寻出来，形成一个个簇。</li></ul><ul><li>对搜寻出来的已知样本进行投票，将各簇下类别最多的分类用作未知样本点的预测。</li></ul><h3 id="3-1、K值的选择"><a href="#3-1、K值的选择" class="headerlink" title="3.1、K值的选择"></a>3.1、K值的选择</h3><p>根据经验发现，不同的𝑘值对模型的预测准确性会有比较大的影响，如果𝑘值过于偏小，可能会导致模型的过拟合；反之，又可能会使模型进入欠拟合状态。</p><p><img src="https://i.loli.net/2019/12/15/UOaQVc6PuwY7k9m.png" alt="不同K值选择导致的结果"></p><p>以芝麻分的例子来说，是选取你所有的好友来推断你的信用呢还是选取经常和你有金钱或信息来往的人进行推断呢？</p><p>目前有两种K值选择方案：</p><ul><li><p>第一种：设置k近邻样本的投票权重，假设读者在使用KNN算法进行分类或预测时设置的k值比较大，担心模型发生欠拟合的现象，一个简单有效的处理办法就是设置近邻样本的投票权重，如果已知样本距离未知样本比较远，则对应的权重就设置得低一些，否则权重就高一些，通常可以将权重设置为距离的倒数。</p></li><li><p>第二种：采用多重交叉验证法，该方法是目前比较流行的方案，其核心就是将k取不同的值，然后在每种值下执行m重的交叉验证，最后选出平均误差最小的k值。</p></li></ul><h3 id="3-2、样本间相似度的度量方法"><a href="#3-2、样本间相似度的度量方法" class="headerlink" title="3.2、样本间相似度的度量方法"></a>3.2、样本间相似度的度量方法</h3><p>前面说到可以根据样本距离的远近设置对应的权重，那么如果计算样本之间的距离呢？一下有三种计算样本间距离的方法：</p><h4 id="3-2-1、欧式距离"><a href="#3-2-1、欧式距离" class="headerlink" title="3.2.1、欧式距离"></a>3.2.1、欧式距离</h4><p><img src="https://i.loli.net/2019/12/15/WlLchdN2BqRgMt4.png" alt="欧氏距离"></p><h4 id="3-2-2、曼哈顿距离"><a href="#3-2-2、曼哈顿距离" class="headerlink" title="3.2.2、曼哈顿距离"></a>3.2.2、曼哈顿距离</h4><p><img src="https://i.loli.net/2019/12/15/jupFbCofr9qhI7e.png" alt="曼哈顿距离"></p><h4 id="3-2-3、余弦相似度"><a href="#3-2-3、余弦相似度" class="headerlink" title="3.2.3、余弦相似度"></a>3.2.3、余弦相似度</h4><p><img src="https://i.loli.net/2019/12/15/KZaG9dCvBTDILfY.png" alt="余弦相似度"></p><h4 id="3-2-4、杰卡德相似系数"><a href="#3-2-4、杰卡德相似系数" class="headerlink" title="3.2.4、杰卡德相似系数"></a>3.2.4、杰卡德相似系数</h4><p>杰卡德相似系数与余弦相似度经常被用于推荐算法，计算用户之间的相似性。例如，A用户购买了10件不同的商品，B用户购买了15件不同的商品，则两者之间的相似系数可以表示为：</p><p>$$J(A,B)=\displaystyle  \frac {|A \cap B|}{|A \cup B|}$$</p><p>其中，|A⋂B|表示两个用户所购买相同商品的数量，|A⋃B|代表两个用户购买所有产品的数量。例如，A用户购买的10件商品中有8件与B用户一致，且两个用户一共购买了17件不同的商品，则它们的杰卡德相似系数为8/17。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KNN </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
